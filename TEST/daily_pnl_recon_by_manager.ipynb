{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>8070.0</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>7830.0</td>\n",
       "      <td>8040.0</td>\n",
       "      <td>8040.0</td>\n",
       "      <td>36353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>7910.0</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>7880.0</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>22736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>7900.0</td>\n",
       "      <td>8050.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>7910.0</td>\n",
       "      <td>7910.0</td>\n",
       "      <td>24768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>8030.0</td>\n",
       "      <td>8830.0</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>8130.0</td>\n",
       "      <td>8130.0</td>\n",
       "      <td>375939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>8050.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>7950.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>44422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>8100.0</td>\n",
       "      <td>8270.0</td>\n",
       "      <td>8010.0</td>\n",
       "      <td>8010.0</td>\n",
       "      <td>8010.0</td>\n",
       "      <td>28047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>8100.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>7870.0</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>23698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>7960.0</td>\n",
       "      <td>8070.0</td>\n",
       "      <td>7870.0</td>\n",
       "      <td>7910.0</td>\n",
       "      <td>7910.0</td>\n",
       "      <td>16837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>7920.0</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>7910.0</td>\n",
       "      <td>7910.0</td>\n",
       "      <td>25688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>7850.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>8010.0</td>\n",
       "      <td>8010.0</td>\n",
       "      <td>66175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>7700.0</td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830.0</td>\n",
       "      <td>42414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>8040.0</td>\n",
       "      <td>8040.0</td>\n",
       "      <td>7540.0</td>\n",
       "      <td>7560.0</td>\n",
       "      <td>7560.0</td>\n",
       "      <td>67786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>7520.0</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>62113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>7770.0</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7880.0</td>\n",
       "      <td>7880.0</td>\n",
       "      <td>31358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>7920.0</td>\n",
       "      <td>8150.0</td>\n",
       "      <td>7890.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>56679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>8120.0</td>\n",
       "      <td>8120.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7960.0</td>\n",
       "      <td>7960.0</td>\n",
       "      <td>39109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>8030.0</td>\n",
       "      <td>7790.0</td>\n",
       "      <td>7920.0</td>\n",
       "      <td>7920.0</td>\n",
       "      <td>25510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>7920.0</td>\n",
       "      <td>7920.0</td>\n",
       "      <td>7720.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>21697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>7750.0</td>\n",
       "      <td>8140.0</td>\n",
       "      <td>7720.0</td>\n",
       "      <td>8070.0</td>\n",
       "      <td>8070.0</td>\n",
       "      <td>166892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>8110.0</td>\n",
       "      <td>8150.0</td>\n",
       "      <td>7690.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>73593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>7750.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>7550.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>29378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>7730.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7530.0</td>\n",
       "      <td>7530.0</td>\n",
       "      <td>27548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01</th>\n",
       "      <td>7540.0</td>\n",
       "      <td>7540.0</td>\n",
       "      <td>7290.0</td>\n",
       "      <td>7380.0</td>\n",
       "      <td>7380.0</td>\n",
       "      <td>47146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-02</th>\n",
       "      <td>7370.0</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>7370.0</td>\n",
       "      <td>7390.0</td>\n",
       "      <td>7390.0</td>\n",
       "      <td>18181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-05</th>\n",
       "      <td>7400.0</td>\n",
       "      <td>7850.0</td>\n",
       "      <td>7320.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>67639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-06</th>\n",
       "      <td>7900.0</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>7660.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>37107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-07</th>\n",
       "      <td>7710.0</td>\n",
       "      <td>7950.0</td>\n",
       "      <td>7710.0</td>\n",
       "      <td>7880.0</td>\n",
       "      <td>7880.0</td>\n",
       "      <td>34695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-08</th>\n",
       "      <td>7880.0</td>\n",
       "      <td>7940.0</td>\n",
       "      <td>7790.0</td>\n",
       "      <td>7850.0</td>\n",
       "      <td>7850.0</td>\n",
       "      <td>18976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close  Adj Close  Volume\n",
       "Date                                                         \n",
       "2024-01-02  8070.0  8080.0  7830.0  8040.0     8040.0   36353\n",
       "2024-01-03  7910.0  8020.0  7880.0  7930.0     7930.0   22736\n",
       "2024-01-04  7900.0  8050.0  7840.0  7910.0     7910.0   24768\n",
       "2024-01-05  8030.0  8830.0  7900.0  8130.0     8130.0  375939\n",
       "2024-01-08  8050.0  8200.0  7950.0  8100.0     8100.0   44422\n",
       "2024-01-09  8100.0  8270.0  8010.0  8010.0     8010.0   28047\n",
       "2024-01-10  8100.0  8100.0  7870.0  8020.0     8020.0   23698\n",
       "2024-01-11  7960.0  8070.0  7870.0  7910.0     7910.0   16837\n",
       "2024-01-12  7920.0  8020.0  7800.0  7910.0     7910.0   25688\n",
       "2024-01-15  7850.0  8100.0  7400.0  8010.0     8010.0   66175\n",
       "2024-01-16  8000.0  8200.0  7700.0  7830.0     7830.0   42414\n",
       "2024-01-17  8040.0  8040.0  7540.0  7560.0     7560.0   67786\n",
       "2024-01-18  7520.0  8080.0  7520.0  7750.0     7750.0   62113\n",
       "2024-01-19  7770.0  8110.0  7760.0  7880.0     7880.0   31358\n",
       "2024-01-22  7920.0  8150.0  7890.0  8000.0     8000.0   56679\n",
       "2024-01-23  8120.0  8120.0  7500.0  7960.0     7960.0   39109\n",
       "2024-01-24  8000.0  8030.0  7790.0  7920.0     7920.0   25510\n",
       "2024-01-25  7920.0  7920.0  7720.0  7750.0     7750.0   21697\n",
       "2024-01-26  7750.0  8140.0  7720.0  8070.0     8070.0  166892\n",
       "2024-01-29  8110.0  8150.0  7690.0  7750.0     7750.0   73593\n",
       "2024-01-30  7750.0  7840.0  7550.0  7750.0     7750.0   29378\n",
       "2024-01-31  7730.0  7750.0  7500.0  7530.0     7530.0   27548\n",
       "2024-02-01  7540.0  7540.0  7290.0  7380.0     7380.0   47146\n",
       "2024-02-02  7370.0  7600.0  7370.0  7390.0     7390.0   18181\n",
       "2024-02-05  7400.0  7850.0  7320.0  7760.0     7760.0   67639\n",
       "2024-02-06  7900.0  7900.0  7660.0  7760.0     7760.0   37107\n",
       "2024-02-07  7710.0  7950.0  7710.0  7880.0     7880.0   34695\n",
       "2024-02-08  7880.0  7940.0  7790.0  7850.0     7850.0   18976"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas_datareader.data as web\n",
    "from mplfinance import plot\n",
    "\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "data = web.get_data_yahoo('290740.KQ', start='2024-01-01', end='2024-02-13')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      240600\n",
      "1      445090\n",
      "2      432470\n",
      "3      446540\n",
      "4      354320\n",
      "5      396470\n",
      "6      432720\n",
      "7      111380\n",
      "8      435620\n",
      "9      378340\n",
      "10     417200\n",
      "14     373170\n",
      "16     095700\n",
      "19     335890\n",
      "21     019170\n",
      "22     060280\n",
      "23     417010\n",
      "24     397030\n",
      "25     287410\n",
      "27     376300\n",
      "28     196170\n",
      "29     006400\n",
      "31     373220\n",
      "33     001570\n",
      "45     068760\n",
      "46     334970\n",
      "48     323990\n",
      "49     145720\n",
      "51     119860\n",
      "54     285800\n",
      "55     274400\n",
      "56     450520\n",
      "59     430690\n",
      "61     336570\n",
      "62     172670\n",
      "65     451760\n",
      "67     298380\n",
      "70     438700\n",
      "71     232830\n",
      "73     443250\n",
      "74     432430\n",
      "79     451220\n",
      "82     086900\n",
      "84     214150\n",
      "86     096530\n",
      "87     047560\n",
      "88     429270\n",
      "89     137400\n",
      "90     241840\n",
      "91     403870\n",
      "92     251340\n",
      "93     252670\n",
      "117    448710\n",
      "120    416180\n",
      "123    454910\n",
      "Name: ticker, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = r'C:\\PythonProjects\\recon\\positions.xlsx'\n",
    "\n",
    "# 'start_position' 시트의 데이터를 불러오기\n",
    "df = pd.read_excel(file_path, sheet_name='start_position', dtype={'ticker': str})\n",
    "\n",
    "# 'ticker' 열의 정보 중 중복된 것 제외하여 가져오기\n",
    "unique_tickers = df['ticker'].drop_duplicates()\n",
    "\n",
    "# 중복 제외된 'ticker' 열의 정보 출력\n",
    "print(unique_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame이 'start' 시트에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from pykrx import stock\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = r'C:\\PythonProjects\\recon\\positions.xlsx'\n",
    "\n",
    "# 'start_position' 시트의 데이터를 불러오기\n",
    "df = pd.read_excel(file_path, sheet_name='start_position', dtype={'ticker': str})\n",
    "\n",
    "# ticker 열의 종목들에 대한 종가 데이터 불러오기\n",
    "closing_prices = []\n",
    "for ticker in df['ticker']:\n",
    "    try:\n",
    "        # pykrx의 get_market_ohlcv_by_date 함수를 사용하여 종가 데이터 불러오기\n",
    "        close_price = stock.get_market_ohlcv_by_date(\"20240101\", \"20240310\", ticker)[\"종가\"][-1]\n",
    "        closing_prices.append(close_price)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for ticker {ticker}: {e}\")\n",
    "        closing_prices.append(None)  # 에러가 발생하면 None으로 처리\n",
    "\n",
    "# 종가 데이터를 데이터프레임에 추가\n",
    "df['closing_price'] = closing_prices\n",
    "\n",
    "# 결과를 'start' 시트에 저장\n",
    "with pd.ExcelWriter(file_path, mode='a', engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, sheet_name='start', index=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"DataFrame이 'start' 시트에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         펀드     매매처    단축코드              종목명 운용역명  매매구분   체결수량      체결단가  \\\n",
      "0   DM12001      KB  335890               비올  정항준   Buy   1570    8582.0   \n",
      "1   DM14001     KIS  335890               비올  정항준   Buy   1623    8579.0   \n",
      "2   DM13001  Yuanta  335890               비올  정항준   Buy   1521    8581.0   \n",
      "3   DM13001  Yuanta  095270          웨이브일렉트로  김대욱   Buy    162    5075.0   \n",
      "4   DM13001    MACQ  241840            에이스토리  김대욱  Sell  11930   13816.0   \n",
      "5   DM12001     HMC  376300              디어유  김대욱  Sell   1500   32292.0   \n",
      "6   DM14001     JPM  376300              디어유  김대욱  Sell   1400   32281.0   \n",
      "7   DM13001    CLSA  047560           이스트소프트  김대욱  Sell   9360   15566.0   \n",
      "8   DM13001    HSBC  119860           커넥트웨이브  김대욱  Sell   1500   16389.0   \n",
      "9   DM13001      GS  376300              디어유  김대욱  Sell   3000   32291.0   \n",
      "10  DM13001      KB  334970      프레스티지바이오로직스  정항준  Sell   1376    4589.0   \n",
      "11  DM13001  Yuanta  403870             HPSP  나용천  Sell   5100   42985.0   \n",
      "12  DM13001  Yuanta  068760           셀트리온제약  정항준   Buy   1011   99963.0   \n",
      "13  DM12001   Mirae  207940         삼성바이오로직스  정항준   Buy     25  783880.0   \n",
      "14  DM14001     KIS  207940         삼성바이오로직스  정항준   Buy     25  784080.0   \n",
      "15  DM13001  Eugene  207940         삼성바이오로직스  정항준   Buy     57  784316.0   \n",
      "16  DM12001      NH  397030          에이프릴바이오  정항준  Sell   1064   16190.0   \n",
      "17  DM14001     KIS  397030          에이프릴바이오  정항준  Sell    965   16193.0   \n",
      "18  DM13001  Yuanta  397030          에이프릴바이오  정항준  Sell   2511   16178.0   \n",
      "19  DM12001      KB  196170             알테오젠  정항준  Sell    281   94094.0   \n",
      "20  DM14001     KIS  196170             알테오젠  정항준  Sell    210   94126.0   \n",
      "21  DM13001  Yuanta  196170             알테오젠  정항준  Sell    621   93832.0   \n",
      "22  DM13001      KB  451760               컨텍  정항준   Buy   2431   16851.0   \n",
      "23  DM12001      KB  354320               알멕  김대욱  Sell    115   45000.0   \n",
      "24  DM12002   Mirae  354320               알멕  김대욱  Sell    376   45023.0   \n",
      "25  DM14001     KIS  354320               알멕  김대욱  Sell    219   45000.0   \n",
      "26  DM13001  Yuanta  354320               알멕  김대욱  Sell    805   45071.0   \n",
      "27  DM11001      NH  354320               알멕  김대욱  Sell    200   45000.0   \n",
      "28  DM13001  Yuanta  232830              시큐센  김대욱  Sell  12539    4975.0   \n",
      "29  DM12001  Yuanta  001570               금양  김대욱  Sell    955  109570.0   \n",
      "30  DM14001     KIS   106V3  코스닥150 F 202403  김대욱  Sell      1    1394.2   \n",
      "31  DM14001     KIS   101V3  코스피200 F 202403  김대욱  Sell      1     360.1   \n",
      "32  DM12001      KB   101V3  코스피200 F 202403  김대욱  Sell      4     359.3   \n",
      "\n",
      "           체결금액  주문번호  \n",
      "0    13473740.0  28.0  \n",
      "1    13923717.0  27.0  \n",
      "2    13051701.0  26.0  \n",
      "3      822150.0  25.0  \n",
      "4   164824880.0  24.0  \n",
      "5    48438000.0  23.0  \n",
      "6    45193400.0  22.0  \n",
      "7   145697760.0  21.0  \n",
      "8    24583500.0  21.0  \n",
      "9    96873000.0  21.0  \n",
      "10    6314464.0  20.0  \n",
      "11  219223500.0  19.0  \n",
      "12  101062593.0  18.0  \n",
      "13   19597000.0  17.0  \n",
      "14   19602000.0  16.0  \n",
      "15   44706012.0  15.0  \n",
      "16   17226160.0  14.0  \n",
      "17   15626245.0  13.0  \n",
      "18   40622958.0  12.0  \n",
      "19   26440414.0  11.0  \n",
      "20   19766460.0  10.0  \n",
      "21   58269672.0   9.0  \n",
      "22   40964781.0   8.0  \n",
      "23    5175000.0   7.0  \n",
      "24   16928648.0   6.0  \n",
      "25    9855000.0   5.0  \n",
      "26   36282155.0   4.0  \n",
      "27    9000000.0   3.0  \n",
      "28   62381525.0   2.0  \n",
      "29  104639350.0   1.0  \n",
      "30          NaN   NaN  \n",
      "31          NaN   NaN  \n",
      "32          NaN   NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일 경로 설정\n",
    "excel_file = r'C:\\PythonProjects\\recon\\거래내역\\1월2일 거래.xlsx'\n",
    "\n",
    "# 엑셀 파일 읽어들이기\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# '펀드' 칼럼 값이 변경\n",
    "df.loc[df['펀드'] == '하이일드', '펀드'] = 'DM11001'\n",
    "df.loc[df['펀드'] == '공모주1호', '펀드'] = 'DM12001'\n",
    "df.loc[df['펀드'] == '공모주2호', '펀드'] = 'DM12002'\n",
    "df.loc[df['펀드'] == '포커스', '펀드'] = 'DM12003'\n",
    "df.loc[df['펀드'] == '코스닥벤처', '펀드'] = 'DM13001'\n",
    "df.loc[df['펀드'] == '멀티전략', '펀드'] = 'DM14001'\n",
    "\n",
    "# '매매구분' 칼럼 값 변경\n",
    "df.loc[df['매매구분'] == 'Buy cover', '매매구분'] = 'Buy'\n",
    "df.loc[df['매매구분'] == 'Sell short', '매매구분'] = 'Sell'\n",
    "\n",
    "# 데이터프레임 확인\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 '2월29일 거래.xlsx'에서 유효하지 않은 날짜를 발견하여 해당 파일을 건너뜁니다.\n",
      "통합된 데이터프레임이 '20240311.xlsx'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 파일들이 있는 경로\n",
    "folder_path = r'C:\\PythonProjects\\recon\\거래내역'\n",
    "\n",
    "# 파일들의 목록 가져오기\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# 엑셀 파일만 필터링\n",
    "excel_files = [file for file in file_list if file.endswith('.xlsx')]\n",
    "\n",
    "# 모든 엑셀 파일을 하나의 데이터프레임으로 통합\n",
    "dfs = []\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "    \n",
    "\n",
    "    # 파일명에서 날짜 추출\n",
    "    file_date = file.split()[0]  # 파일명에서 첫 번째 단어(날짜 부분) 추출\n",
    "    file_date = file_date.replace('월', '-').replace('일', '')  # '월'과 '일'을 '-'로 변경\n",
    "    \n",
    "    try:\n",
    "        # 날짜 형식 변경 시도\n",
    "        file_date = pd.to_datetime(file_date, format='%m-%d').strftime('%Y-%m-%d')\n",
    "        \n",
    "        # 날짜가 유효한지 검증\n",
    "        datetime.strptime(file_date, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        # 유효하지 않은 날짜이면 건너뛰고 다음 파일 처리\n",
    "        print(f\"파일 '{file}'에서 유효하지 않은 날짜를 발견하여 해당 파일을 건너뜁니다.\")\n",
    "        continue\n",
    "    \n",
    "    # 연도를 '2024'로 변경\n",
    "    file_date = file_date.replace('1900', '2024')\n",
    "    \n",
    "    # 데이터프레임에 날짜 열 추가\n",
    "    df.insert(0, '날짜', file_date)\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "s\n",
    "# 통합된 데이터프레임을 엑셀 파일로 저장\n",
    "output_file = os.path.join(folder_path, '20240311.xlsx')\n",
    "merged_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"통합된 데이터프레임이 '20240311.xlsx'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 '2월29일 거래.xlsx'에서 유효하지 않은 날짜를 발견하여 해당 파일을 건너뜁니다.\n",
      "통합된 데이터프레임이 '20240311.xlsx'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 파일들이 있는 경로\n",
    "folder_path = r'C:\\PythonProjects\\recon\\거래내역'\n",
    "\n",
    "# 파일들의 목록 가져오기\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# 엑셀 파일만 필터링\n",
    "excel_files = [file for file in file_list if file.endswith('.xlsx')]\n",
    "\n",
    "# 모든 엑셀 파일을 하나의 데이터프레임으로 통합\n",
    "dfs = []\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # 파일명에서 날짜 추출\n",
    "    file_date = file.split()[0]  # 파일명에서 첫 번째 단어(날짜 부분) 추출\n",
    "    file_date = file_date.replace('월', '-').replace('일', '')  # '월'과 '일'을 '-'로 변경\n",
    "    \n",
    "    # '펀드' 칼럼 값이 변경\n",
    "    df.loc[df['펀드'] == '하이일드', '펀드'] = 'DM11001'\n",
    "    df.loc[df['펀드'] == '공모주1호', '펀드'] = 'DM12001'\n",
    "    df.loc[df['펀드'] == '공모주2호', '펀드'] = 'DM12002'\n",
    "    df.loc[df['펀드'] == '포커스', '펀드'] = 'DM12003'\n",
    "    df.loc[df['펀드'] == '코스닥벤처', '펀드'] = 'DM13001'\n",
    "    df.loc[df['펀드'] == '멀티전략', '펀드'] = 'DM14001'\n",
    "\n",
    "    try:\n",
    "        # 날짜 형식 변경 시도\n",
    "        file_date = pd.to_datetime(file_date, format='%m-%d').strftime('%Y-%m-%d')\n",
    "        \n",
    "        # 연도를 '2024'로 변경\n",
    "        file_date = file_date.replace(file_date[:4], '2024')\n",
    "    except ValueError:\n",
    "        # 유효하지 않은 날짜이면 건너뛰고 다음 파일 처리\n",
    "        print(f\"파일 '{file}'에서 유효하지 않은 날짜를 발견하여 해당 파일을 건너뜁니다.\")\n",
    "        continue\n",
    "    \n",
    "    # 데이터프레임에 날짜 열 추가\n",
    "    df.insert(0, '날짜', file_date)\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 통합된 데이터프레임을 엑셀 파일로 저장\n",
    "output_file = os.path.join(folder_path, '20240311.xlsx')\n",
    "merged_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"통합된 데이터프레임이 '20240311.xlsx'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터프레임이 'tx_data.xlsx'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일 경로\n",
    "file_path = r'C:\\PythonProjects\\recon\\거래내역\\20240311.xlsx'\n",
    "\n",
    "# 엑셀 파일 읽기\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 4번째 열(column) 선택 후 문자열로 변환하여 저장\n",
    "df.iloc[:, 3] = df.iloc[:, 3].apply(lambda x: str(x).zfill(6))\n",
    "\n",
    "# 데이터프레임을 'tx_data.xlsx'로 저장\n",
    "output_file_path = 'tx_data.xlsx'\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(\"데이터프레임이 'tx_data.xlsx'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import uuid\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "my_id = uuid.uuid4()\n",
    "timestamp = int(time.time())\n",
    "\n",
    "def get_stock_info():\n",
    "    \n",
    "\n",
    "\n",
    "def get_account_num(_alias):\n",
    "    search_url = \"http://3.34.197.25:13010/search\"\n",
    "    params = {\n",
    "        \"accountId\": _alias,\n",
    "    }\n",
    "    response_1 = requests.get(url=search_url, params=params).json()[\"body\"][\"accountId\"]\n",
    "    print(response_1)\n",
    "    return response_1\n",
    "\n",
    "def get_trade_data(ticker, start, end):\n",
    "    \n",
    "    search_trade_url = \"http://3.34.197.25:13020/candlestick/day-candles/\"\n",
    "\n",
    "    params = {\n",
    "        \"ticker\": ticker,\n",
    "        \"from\": start,\n",
    "        \"to\": end\n",
    "    }\n",
    "    \n",
    "    closingPrice_data = requests.get(url=search_trade_url, params=params).json()[\"body\"]\n",
    "\n",
    "    target_orders = []\n",
    "\n",
    "    for item in trade_data:\n",
    "        orders = item.get('orders', [])\n",
    "        for order in orders:\n",
    "            if order.get('ticker') == target_ticker:\n",
    "                position_id = order.get('positionId')\n",
    "                nickname = get_member_nick(position_id)\n",
    "                order['nickname'] = nickname\n",
    "\n",
    "                target_orders.append(order)\n",
    "\n",
    "    print(\"Orders with ticker '{}':\".format(target_ticker))\n",
    "\n",
    "    for order in target_orders:\n",
    "        print(order)\n",
    "\n",
    "    return trade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on datetime64[ns] and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m df2_subset \u001b[39m=\u001b[39m df2[[\u001b[39m\"\u001b[39m\u001b[39m날짜\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m펀드\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m종목명\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m운용역명\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m     17\u001b[0m \u001b[39m# 첫 번째 표에 운용역 데이터를 추가하기 위해 조건에 맞는 행을 찾아서 병합\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m merged_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(df1, df2_subset, how\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m\"\u001b[39;49m, left_on\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m일자\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m펀드코드\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m종목명\u001b[39;49m\u001b[39m\"\u001b[39;49m], right_on\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m날짜\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m펀드\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m종목명\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     20\u001b[0m \u001b[39m# 병합된 데이터프레임을 엑셀 파일로 저장\u001b[39;00m\n\u001b[0;32m     21\u001b[0m merged_df\u001b[39m.\u001b[39mto_excel(\u001b[39m\"\u001b[39m\u001b[39m병합된_엑셀_파일.xlsx\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jtlee\\AppData\\Local\\Programs\\Python\\Python39-32\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[0;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\jtlee\\AppData\\Local\\Programs\\Python\\Python39-32\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:707\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[0;32m    703\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_coerce_merge_keys()\n\u001b[0;32m    709\u001b[0m \u001b[39m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[39m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[39m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[39mif\u001b[39;00m validate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jtlee\\AppData\\Local\\Programs\\Python\\Python39-32\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1344\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[39m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \u001b[39melif\u001b[39;00m needs_i8_conversion(lk\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m needs_i8_conversion(rk\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m-> 1344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1345\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m needs_i8_conversion(lk\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m needs_i8_conversion(rk\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m   1346\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on datetime64[ns] and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path_df1 = r'C:\\PythonProjects\\recon\\hints\\hints_20240311.xlsx'\n",
    "file_path_df2 = r'C:\\PythonProjects\\recon\\hints\\tx_data.xlsx'\n",
    "\n",
    "\n",
    "# 첫 번째 엑셀 파일을 읽어들임\n",
    "df1 = pd.read_excel(file_path_df1)\n",
    "\n",
    "# 두 번째 엑셀 파일을 읽어들임\n",
    "df2 = pd.read_excel(file_path_df2)\n",
    "\n",
    "# \"날짜\" 열의 데이터 유형을 datetime64[ns]로 변환\n",
    "df2['날짜'] = pd.to_datetime(df2['날짜'])\n",
    "\n",
    "# 두 번째 표에서 필요한 열만 선택하여 새로운 데이터프레임 생성\n",
    "df2_subset = df2[[\"날짜\", \"펀드\", \"종목명\", \"운용역명\"]]\n",
    "\n",
    "# 첫 번째 표에 운용역 데이터를 추가하기 위해 조건에 맞는 행을 찾아서 병합\n",
    "merged_df = pd.merge(df1, df2_subset, how=\"left\", left_on=[\"일자\", \"펀드코드\", \"종목명\"], right_on=[\"날짜\", \"펀드\", \"종목명\"])\n",
    "\n",
    "# 병합된 데이터프레임을 엑셀 파일로 저장\n",
    "merged_df.to_excel(\"merged_data.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8579af7ac4b619c1ff9c21d522b2628fe82b49ca1810dac575e63d57c7a67b1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
